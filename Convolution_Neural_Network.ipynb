{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vp0y68YLm9Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe147fc8-2925-49fe-b3c0-a33c8f1ab470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x #specifying the tf version i want to use\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "from tensorflow.keras.layers import Flatten,Conv2D,Dense,MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n"
      ],
      "metadata": {
        "id": "ChKT9PdDnIej"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The MNIST Fashion dataset is installed with keras read more about the dataset at:https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "fashion_mnist = keras.datasets.fashion_mnist # loading the dataset containing images\n",
        "(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "id": "p1OXxWSenlv1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((train_images.shape[0],28,28,1))\n",
        "test_images = test_images.reshape((test_images.shape[0],28,28,1))\n"
      ],
      "metadata": {
        "id": "r1W4SZ4Hq-ed"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with images, we need a tensor with 4 dimensions: batch size, width, height, and color channels.\n",
        "\n",
        "x_train is (60000, 28, 28). We need to reshape it to add the missing dimension (\"1\" because these images are grayscale.)"
      ],
      "metadata": {
        "id": "pznwlI_gmfcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((train_images.shape[0],28,28,1))"
      ],
      "metadata": {
        "id": "bQVsoVkdm63v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each pixel goes from 0 to 255. Neural networks work much better with smaller values.\n",
        "\n",
        "Here we normalize pixels by dividing them by 255. That way, each pixel will go from 0 to 1."
      ],
      "metadata": {
        "id": "JPXrwUKolV2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7zmkx37Emr-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "OxBNiDXOL4AZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line one-hot encodes these values.\n",
        "\n",
        "For example, this will transform a value like 5, in an array of zeros with a single 1 corresponding to the fifth index:\n",
        "\n",
        "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "q1At1Hcyoe_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels)"
      ],
      "metadata": {
        "id": "_DEVWziDmabX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now define our model.There are several ways to create a model in Keras. This one is called the \"Sequential API\". Our model will be a sequence of layers that we will define one by one.\n",
        "\n",
        "A lot is going on with this first line.First, we define our model's input shape: a 28x28x1 tensor (width, height, channels.).This is exactly the shape we have in our train dataset.\n",
        "\n",
        "Then we define our first layer: a Conv2D layer with 32 filters and a 3x3 kernel.This layer will generate 32 different representations using the training images. We also need to define the activation function used for this layer: ReLU.You'll see ReLU everywhere. It's a popular activation function.It will allow us to solve non-linear problems, like recognizing handwritten digits (the train_labes and test_labels).\n",
        "\n",
        "After our Conv2D layer, we have a max pooling operation.The goal of this layer is to downsample the amount of information collected by the convolutional layer.We want to throw away unimportant details and retain what truly matters.\n",
        "\n",
        "We are now going to flatten the output. We want everything in a continuous list of values.That's what the Flatten layer does. It will give us a flat tensor.\n",
        "\n",
        "Finally, we have a couple of Dense layers. Notice how the output layer has a size of 10, one for each of our possible digit values, and a softmax activation. The softmax ensures we get a probability distribution indicating the most likely digit in the image.\n"
      ],
      "metadata": {
        "id": "oUhUGrT1pHHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Buiding the model\n",
        "model = keras.models.Sequential ([\n",
        "    Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(100,activation='relu'),\n",
        "    Dense(10,activation='softmax')\n",
        "\n",
        "    \n",
        "])"
      ],
      "metadata": {
        "id": "fug4dYtqmYZs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating our model, we compile it.I'm using Stochastic Gradient Descent (SGD) as the optimizer.The loss is categorical cross-entropy: this is a multi-class classification problem.We want to record the accuracy as the model trains."
      ],
      "metadata": {
        "id": "fDoPMPRH-RWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compling the model\n",
        "optimizer = SGD(learning_rate=0.01,momentum=0.0)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "MFnNpCGEufTy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we fit the model. This starts training it.A couple of notes:\n",
        "\n",
        "• I'm using a batch size of 32 images.\n",
        "• I'm running 10 total epochs.\n",
        "\n",
        "When fit() is done, we have a fully trained model!\n"
      ],
      "metadata": {
        "id": "0FeuVorX-tsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images,train_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "ylzKROf-vrnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets a random image from the test set and displays it.\n",
        "Notice that we want the image to come from the test set, containing data the model didn't see during training."
      ],
      "metadata": {
        "id": "8ZA6HiUB_0gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = random.choice(test_images)\n",
        "plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
        "plt.show"
      ],
      "metadata": {
        "id": "bt4ilZaE9pmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can't forget to reshape and normalize the image as we did before with the entire train set.\n",
        "\n",
        "I'm doing it this time for the image I use to test the model."
      ],
      "metadata": {
        "id": "3j-_3f2PHtFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = (image.reshape((1,28,28,1))).astype('float32') /255.0"
      ],
      "metadata": {
        "id": "WKgkmWjGGceS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, I predict the value of the image.\n",
        "\n",
        "Remember that the result is a one-hot-encoded vector. That's why I take the argmax value (the position with the highest probability) and that's the result"
      ],
      "metadata": {
        "id": "AtVfkkO0Hy6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digit = np.argmax(model.predict(image)[0],axis=-1)\n",
        "print(\"prediction:\",digit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCwqvLZhHNMF",
        "outputId": "94a70031-532f-4ed3-c593-e834cb42ffe9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: 5\n"
          ]
        }
      ]
    }
  ]
}